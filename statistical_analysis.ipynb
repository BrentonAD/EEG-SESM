{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_DICT = {\n",
    "    0: \"W\",\n",
    "    1: \"N1\",\n",
    "    2: \"N2\",\n",
    "    3: \"N3\",\n",
    "    4: \"REM\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = CLASS_DICT.values()\n",
    "\n",
    "results = []\n",
    "classwise_results = []\n",
    "for model, split in product([\"SESM\",\"EEGNet\"],[1,2,3]):\n",
    "    path = f\"/Users/brenton/Library/CloudStorage/OneDrive-Personal/Documents/_UNIVERSITY/_MASTEROFAI/2024Tri1/Results/{model}/split{split}/\"\n",
    "    \n",
    "    with open(f'{path}/y_true_test.pkl','rb') as f:\n",
    "            y_true = pickle.load(f)\n",
    "        \n",
    "    with open(f'{path}/y_pred_test.pkl','rb') as f:\n",
    "            y_pred = pickle.load(f)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "    row = {\n",
    "        \"split\": split,\n",
    "        \"model\": model,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "    results.append(row)\n",
    "\n",
    "    # Create a confusion matrix\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    class_accuracy = confusion.diagonal()/confusion.sum(axis=1)\n",
    "\n",
    "    classwise_row = { class_name: class_accuracy[i] for i, class_name in enumerate(class_names) }\n",
    "    classwise_row[\"split\"] = split\n",
    "    classwise_row[\"model\"] = model\n",
    "    classwise_results.append(classwise_row)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "classwise_df = pd.DataFrame(classwise_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = results_df.groupby(\"model\")\n",
    "\n",
    "# Separate the data for the two models\n",
    "sesm_data = grouped.get_group('SESM')\n",
    "eegnet_data = grouped.get_group('EEGNet')\n",
    "\n",
    "# Perform t-tests for each metric\n",
    "accuracy_ttest = stats.ttest_ind(sesm_data['accuracy'], eegnet_data['accuracy'])\n",
    "precision_ttest = stats.ttest_ind(sesm_data['precision'], eegnet_data['precision'])\n",
    "recall_ttest = stats.ttest_ind(sesm_data['recall'], eegnet_data['recall'])\n",
    "\n",
    "# Create the resulting DataFrame\n",
    "t_test_results = pd.DataFrame({\n",
    "    'metric': ['accuracy', 'precision', 'recall'],\n",
    "    'statistic': [accuracy_ttest.statistic, precision_ttest.statistic, recall_ttest.statistic],\n",
    "    'p_value': [accuracy_ttest.pvalue, precision_ttest.pvalue, recall_ttest.pvalue]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>5.277954</td>\n",
       "      <td>0.006179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>1.020844</td>\n",
       "      <td>0.365045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>-2.208778</td>\n",
       "      <td>0.091751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  statistic   p_value\n",
       "0   accuracy   5.277954  0.006179\n",
       "1  precision   1.020844  0.365045\n",
       "2     recall  -2.208778  0.091751"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01853612, 0.36504495, 0.13762632])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.false_discovery_control(t_test_results[\"p_value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class wise accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = classwise_df.groupby(\"model\")\n",
    "\n",
    "# Separate the data for the two models\n",
    "sesm_data = grouped.get_group('SESM')\n",
    "eegnet_data = grouped.get_group('EEGNet')\n",
    "\n",
    "# Perform t-tests for each metric\n",
    "classwise_test_results = []\n",
    "for class_name in class_names:\n",
    "    t_test = stats.ttest_ind(sesm_data[class_name], eegnet_data[class_name])\n",
    "    classwise_test_results.append(t_test)\n",
    "\n",
    "# Create the resulting DataFrame\n",
    "classwise_t_test_results = pd.DataFrame({\n",
    "    'metric': class_names,\n",
    "    'statistic': [test.statistic for test in classwise_test_results],\n",
    "    'p_value': [test.pvalue for test in classwise_test_results]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.517189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1</td>\n",
       "      <td>-10.160507</td>\n",
       "      <td>0.000528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N2</td>\n",
       "      <td>2.616859</td>\n",
       "      <td>0.058994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N3</td>\n",
       "      <td>-1.960218</td>\n",
       "      <td>0.121524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REM</td>\n",
       "      <td>0.359580</td>\n",
       "      <td>0.737341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric  statistic   p_value\n",
       "0      W   0.709489  0.517189\n",
       "1     N1 -10.160507  0.000528\n",
       "2     N2   2.616859  0.058994\n",
       "3     N3  -1.960218  0.121524\n",
       "4    REM   0.359580  0.737341"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classwise_t_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64648622, 0.00264193, 0.14748384, 0.20254033, 0.73734121])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.false_discovery_control(classwise_t_test_results[\"p_value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted Class: W\n",
    "1.4668883\n",
    "16\n",
    "0.5166144\n",
    "TtestResult(statistic=4.0880449087745285, pvalue=0.00013340474855422295, df=59.0)\n",
    "\n",
    "\n",
    "Predicted Class: N2\n",
    "1.4572722\n",
    "109\n",
    "0.43939048\n",
    "TtestResult(statistic=10.255296820669766, pvalue=8.447303667041605e-22, df=357.0)\n",
    "\n",
    "\n",
    "Predicted Class: N3\n",
    "1.4774722\n",
    "7\n",
    "0.43798834\n",
    "TtestResult(statistic=2.3111056661108242, pvalue=0.032880124854366775, df=18.0)\n",
    "\n",
    "\n",
    "Predicted Class: REM\n",
    "1.7485868\n",
    "66\n",
    "0.4953538\n",
    "TtestResult(statistic=10.495021118314252, pvalue=1.4186766905306205e-21, df=249.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.77872998e-04, 2.83735338e-21, 3.28801249e-02, 2.83735338e-21])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.false_discovery_control([0.00013340474855422295,8.447303667041605e-22,0.032880124854366775,1.4186766905306205e-21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEGNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
